{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for model, tokenizer, and checkpoints\n",
    "model_save_path = \"../Model/savedModel/savedModel_12500\"\n",
    "tokenizer_save_path = \"../Model/savedTokenizer/savedModel_12500\"\n",
    "checkpoint_path = \"../Model/checkpoint.pth\"\n",
    "\n",
    "epochs = 6  \n",
    "batch_size = 32  \n",
    "gradient_accumulation_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_and_tokenizer():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-2-7b-hf\", num_labels=2)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation():\n",
    "    data = pd.read_csv(\"../Datasets/dataset_12500.csv\")\n",
    "    text_data = data[\"url\"]\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "    max_length = 128\n",
    "    tokenized_data = tokenizer(text_data.tolist(), padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    X_text = tokenized_data[\"input_ids\"]\n",
    "    y = data[\"label\"].apply(lambda x: 1 if x == \"bad\" else 0)\n",
    "\n",
    "    X_train_text, X_test_text, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "    train_dataset = TensorDataset(X_train_text, torch.tensor(y_train.values, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(X_test_text, torch.tensor(y_test.values, dtype=torch.long))\n",
    "    \n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_setup(train_dataset, test_dataset, batch_size, rank):\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, num_replicas=world_size, rank=rank)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch, sampler=train_sampler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def collate_batch(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    labels = torch.tensor(labels)\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler):\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        return checkpoint['epoch']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def plot_metrics(epochs, train_losses, test_accuracies, test_precisions, test_recalls, test_f1_scores):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs_range = range(1, epochs + 1)\n",
    "\n",
    "    plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs_range, test_accuracies, label='Test Accuracy')\n",
    "    plt.plot(epochs_range, test_precisions, label='Test Precision')\n",
    "    plt.plot(epochs_range, test_recalls, label='Test Recall')\n",
    "    plt.plot(epochs_range, test_f1_scores, label='Test F1 Score')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.title('Training and Test Metrics Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, world_size):\n",
    "    try:\n",
    "        setup(rank, world_size)\n",
    "\n",
    "        model, tokenizer = model_and_tokenizer()\n",
    "        train_dataset, test_dataset = data_preparation()\n",
    "        train_loader, test_loader = data_loader_setup(\n",
    "            train_dataset, test_dataset, batch_size=16, rank=rank\n",
    "        )\n",
    "\n",
    "        device = torch.device(\"cuda:{}\".format(rank))\n",
    "        model.to(device)\n",
    "        model = DDP(model, device_ids=[rank])\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs\n",
    "        )\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        train_losses = []\n",
    "        test_accuracies = []\n",
    "        test_precisions = []\n",
    "        test_recalls = []\n",
    "        test_f1_scores = []\n",
    "\n",
    "        # Load checkpoint if available\n",
    "        start_epoch = load_checkpoint(model, optimizer, scheduler)\n",
    "\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for step, (texts, labels) in enumerate(train_loader):\n",
    "                texts = texts.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(texts, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Perform Gradient Accumulation\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            average_loss = total_loss / len(train_loader)\n",
    "            train_losses.append(average_loss)\n",
    "\n",
    "            if rank == 0:\n",
    "                # Evaluation loop\n",
    "                model.eval()\n",
    "                predictions = []\n",
    "                true_labels = []\n",
    "                with torch.no_grad():\n",
    "                    for texts, labels in test_loader:\n",
    "                        texts = texts.to(device)\n",
    "                        labels = labels.to(device)\n",
    "\n",
    "                        with autocast():\n",
    "                            outputs = model(texts, labels=labels)\n",
    "                            logits = outputs.logits\n",
    "                            _, predicted_labels = torch.max(logits, dim=1)\n",
    "\n",
    "                        predictions.extend(predicted_labels.cpu().numpy())\n",
    "                        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                accuracy = accuracy_score(true_labels, predictions)\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                    true_labels, predictions, average=\"binary\"\n",
    "                )\n",
    "\n",
    "                test_accuracies.append(accuracy)\n",
    "                test_precisions.append(precision)\n",
    "                test_recalls.append(recall)\n",
    "                test_f1_scores.append(f1)\n",
    "                print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "                print(f\"Precision: {precision:.4f}\")\n",
    "                print(f\"Recall: {recall:.4f}\")\n",
    "                print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "                metrics_df = pd.DataFrame(\n",
    "                    [[accuracy, precision, recall, f1]],\n",
    "                    columns=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
    "                )\n",
    "                print(metrics_df)\n",
    "                metrics_df.to_csv(\"Evaluation_dataset_12500.csv\", index=False)\n",
    "\n",
    "                # Save checkpoint after each epoch\n",
    "                save_checkpoint(epoch + 1, model.module, optimizer, scheduler)\n",
    "\n",
    "        if rank == 0:\n",
    "            plot_metrics(\n",
    "                epochs,\n",
    "                train_losses,\n",
    "                test_accuracies,\n",
    "                test_precisions,\n",
    "                test_recalls,\n",
    "                test_f1_scores,\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in process {rank}: {e}\")\n",
    "        traceback.print_exc() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     mp\u001b[38;5;241m.\u001b[39mspawn(train, args\u001b[38;5;241m=\u001b[39m(world_size,), nprocs\u001b[38;5;241m=\u001b[39mworld_size, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     world_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WSH3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\multiprocessing\\spawn.py:246\u001b[0m, in \u001b[0;36mspawn\u001b[1;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[0;32m    240\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m start_method\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    245\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WSH3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\multiprocessing\\spawn.py:202\u001b[0m, in \u001b[0;36mstart_processes\u001b[1;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WSH3\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\multiprocessing\\spawn.py:153\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[0;32m    146\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[0;32m    147\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    151\u001b[0m         )\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[0;32m    155\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m    156\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[0;32m    157\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    160\u001b[0m original_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_queues[error_index]\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    161\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n",
      "\u001b[1;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
